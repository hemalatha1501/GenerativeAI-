{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_mn55uY0NWi"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries\n",
        "!pip install transformers faiss-cpu sentence-transformers --quiet\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import faiss\n",
        "import numpy as np\n",
        "cases = [\n",
        "{\"case_id\": 1, \"title\": \"Fraud Investigation\", \"summary\": \"A case involving financial fraud where an individual defrauded investors.\", \"full_text\": \"Detailed legal text about the fraud investigation...\"},\n",
        "{\"case_id\": 2, \"title\": \"Tax Evasion\", \"summary\": \"A case related to a company that evaded taxes for several years, resulting in legal action.\", \"full_text\": \"Full legal document about the tax evasion case...\"},\n",
        "{\"case_id\": 3, \"title\": \"Breach of Contract\", \"summary\": \"A business partnership ended due to a breach of contract, leading to a lawsuit.\", \"full_text\": \"Complete legal document regarding breach of contract...\"},\n",
        "{\"case_id\": 4, \"title\": \"Personal Injury Claim\", \"summary\": \"A personal injury claim filed against a company for unsafe work conditions.\", \"full_text\": \"Full legal document related to the personal injury claim...\"},\n",
        "{\"case_id\": 5, \"title\": \"Trademark Infringement\", \"summary\": \"A dispute over trademark infringement between two clothing brands.\", \"full_text\": \"Full legal document detailing the trademark infringement case...\"},\n",
        "{\"case_id\": 6, \"title\": \"Cybercrime Investigation\", \"summary\": \"A case involving hacking and theft of data from a major corporation.\", \"full_text\": \"Legal document detailing the cybercrime investigation...\"},\n",
        "{\"case_id\": 7, \"title\": \"Real Estate Fraud\", \"summary\": \"A case about fraudulent real estate transactions involving falsified property documents.\", \"full_text\": \"Complete legal text regarding real estate fraud...\"},\n",
        "{\"case_id\": 8, \"title\": \"Insurance Dispute\", \"summary\": \"A dispute between an insurance company and a claimant over coverage of damages.\", \"full_text\": \"Legal text detailing the insurance dispute case...\"}\n",
        "]\n",
        "case_summaries = [case['summary'] for case in cases]\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"nlpaueb/legal-bert-base-uncased\")\n",
        "model = AutoModel.from_pretrained(\"nlpaueb/legal-bert-base-uncased\")\n",
        "model = model.to('cuda') # Move the model to GPU for faster processing\n",
        "def embed_text(text):\n",
        "  inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "  inputs = {key: val.to('cuda') for key, val in inputs.items()} # Move inputs to GPU\n",
        "  with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "  return outputs.last_hidden_state.mean(dim=1).cpu()\n",
        "case_embeddings = torch.stack([embed_text(summary) for summary in case_summaries])\n",
        "case_embeddings_np = case_embeddings.numpy().reshape(len(case_summaries), -1)\n",
        "index = faiss.IndexFlatL2(case_embeddings_np.shape[1])\n",
        "index.add(case_embeddings_np) # Add the precomputed embeddings to the FAISS index\n",
        "def search_cases(query, index, cases, top_n=5):\n",
        "  query_embedding = embed_text(query).numpy().reshape(1, -1)\n",
        "  distances, indices = index.search(query_embedding, top_n)\n",
        "  return [cases[i] for i in indices[0]] # Return the cases corresponding to the top N indices\n",
        "user_query = input(\"Enter your legal query: \")\n",
        "results = search_cases(user_query, index, cases, top_n=5)\n",
        "for result in results:\n",
        "  print(f\"Case Title: {result['title']}\")\n",
        "  print(f\"Summary: {result['summary']}\")\n",
        "  print(f\"Full Text: {result['full_text'][:500]}...\") # Show the first 500 characters of the full text\n",
        "  print(\"\\n\")"
      ]
    }
  ]
}